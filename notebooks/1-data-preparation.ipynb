{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation for GRI Calculation with Global Dialogues Data\n",
    "\n",
    "This notebook demonstrates how to prepare data for Global Representativeness Index (GRI) calculations using the **new GRI module structure**.\n",
    "\n",
    "## What's New\n",
    "\n",
    "This updated notebook showcases the improved data loading workflow:\n",
    "- **`gri.data_loader`** module for unified data loading\n",
    "- **`gri.validation`** module for comprehensive data validation\n",
    "- **`load_benchmark_suite()`** to load all benchmarks at once\n",
    "- **`load_gd_survey()`** for automated Global Dialogues processing\n",
    "\n",
    "## Overview\n",
    "\n",
    "The GRI system requires two types of data:\n",
    "1. **Benchmark data**: Global population demographics from UN and Pew Research\n",
    "2. **Survey data**: Participant demographics from surveys like Global Dialogues\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "First, ensure you have processed the benchmark data:\n",
    "```bash\n",
    "make process-data\n",
    "```\n",
    "\n",
    "This creates benchmark files for all 13 configured dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:26.628039Z",
     "iopub.status.busy": "2025-06-13T07:18:26.627878Z",
     "iopub.status.idle": "2025-06-13T07:18:27.042882Z",
     "shell.execute_reply": "2025-06-13T07:18:27.042267Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the gri module to the path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import the new GRI module functions\n",
    "from gri.data_loader import load_benchmark_suite, load_gd_survey\n",
    "from gri.validation import validate_benchmark_data, validate_survey_data\n",
    "from gri.config import GRIConfig\n",
    "\n",
    "# Set pandas display options for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Initialize configuration\n",
    "config = GRIConfig()\n",
    "print(\"‚úÖ GRI module loaded successfully\")\n",
    "print(f\"üìã Configured dimensions: {len(config.get_all_dimensions())}\")\n",
    "print(f\"üìÅ Data directory: {Path('../data/processed').absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Benchmark Data with `load_benchmark_suite()`\n",
    "\n",
    "The new `load_benchmark_suite()` function loads all benchmark data files at once, returning a dictionary mapped by dimension name. This is much more convenient than loading files individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.100784Z",
     "iopub.status.busy": "2025-06-13T07:18:27.099400Z",
     "iopub.status.idle": "2025-06-13T07:18:27.140156Z",
     "shell.execute_reply": "2025-06-13T07:18:27.139453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load all benchmark data at once\n",
    "print(\"Loading benchmark suite...\")\n",
    "benchmarks = load_benchmark_suite(data_dir='../data/processed')\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(benchmarks)} benchmark dimensions:\")\n",
    "for i, (dimension, df) in enumerate(benchmarks.items(), 1):\n",
    "    print(f\"{i:2d}. {dimension}: {len(df):,} strata\")\n",
    "\n",
    "# Verify all proportions sum to 1.0\n",
    "print(\"\\nüîç Verifying benchmark data quality:\")\n",
    "for dimension, df in benchmarks.items():\n",
    "    prop_sum = df['population_proportion'].sum()\n",
    "    status = \"‚úÖ\" if abs(prop_sum - 1.0) < 0.001 else \"‚ö†Ô∏è\"\n",
    "    print(f\"{status} {dimension}: sum = {prop_sum:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.147498Z",
     "iopub.status.busy": "2025-06-13T07:18:27.146694Z",
     "iopub.status.idle": "2025-06-13T07:18:27.161557Z",
     "shell.execute_reply": "2025-06-13T07:18:27.160099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Examine structure of core benchmark dimensions\n",
    "core_dimensions = ['Country √ó Gender √ó Age', 'Country √ó Religion', 'Country √ó Environment']\n",
    "\n",
    "for dimension in core_dimensions:\n",
    "    if dimension in benchmarks:\n",
    "        df = benchmarks[dimension]\n",
    "        print(f\"\\nüìä {dimension} Structure:\")\n",
    "        print(f\"   Columns: {list(df.columns)}\")\n",
    "        print(f\"   Sample data:\")\n",
    "        print(df.head(3).to_string())\n",
    "        \n",
    "        # Show unique values for each categorical column\n",
    "        categorical_cols = [col for col in df.columns if col != 'population_proportion']\n",
    "        for col in categorical_cols[:3]:  # Show first 3 categorical columns\n",
    "            unique_vals = df[col].nunique()\n",
    "            print(f\"   Unique {col}: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.166880Z",
     "iopub.status.busy": "2025-06-13T07:18:27.166227Z",
     "iopub.status.idle": "2025-06-13T07:18:27.177708Z",
     "shell.execute_reply": "2025-06-13T07:18:27.176283Z"
    }
   },
   "outputs": [],
   "source": [
    "## 2. Validate Benchmark Data\n",
    "\n",
    "The new `validate_benchmark_data()` function checks for common data quality issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.183597Z",
     "iopub.status.busy": "2025-06-13T07:18:27.182995Z",
     "iopub.status.idle": "2025-06-13T07:18:27.194544Z",
     "shell.execute_reply": "2025-06-13T07:18:27.193618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validate each benchmark dimension\n",
    "print(\"üîç Running benchmark validation...\\n\")\n",
    "\n",
    "validation_results = {}\n",
    "for dimension, df in benchmarks.items():\n",
    "    is_valid, issues = validate_benchmark_data(df)\n",
    "    validation_results[dimension] = (is_valid, issues)\n",
    "    \n",
    "    if is_valid:\n",
    "        print(f\"‚úÖ {dimension}: Valid\")\n",
    "    else:\n",
    "        print(f\"‚ùå {dimension}: {len(issues)} issues found\")\n",
    "        for issue in issues:\n",
    "            print(f\"   - {issue}\")\n",
    "\n",
    "# Summary\n",
    "valid_count = sum(1 for is_valid, _ in validation_results.values() if is_valid)\n",
    "print(f\"\\nüìä Validation Summary: {valid_count}/{len(benchmarks)} dimensions passed validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Global Dialogues Survey Data with `load_gd_survey()`\n",
    "\n",
    "The new `load_gd_survey()` function handles all the complexity of loading Global Dialogues data:\n",
    "- Detects and handles format quirks (malformed headers, etc.)\n",
    "- Applies segment mappings automatically\n",
    "- Adds geographic hierarchies (region, continent)\n",
    "- Standardizes column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.199649Z",
     "iopub.status.busy": "2025-06-13T07:18:27.198609Z",
     "iopub.status.idle": "2025-06-13T07:18:27.298799Z",
     "shell.execute_reply": "2025-06-13T07:18:27.298368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Global Dialogues survey data using the new function\n",
    "gd_path = Path(\"../data/raw/survey_data/global-dialogues/Data/GD3/GD3_participants.csv\")\n",
    "\n",
    "if gd_path.exists():\n",
    "    print(f\"üìÇ Loading GD3 data from: {gd_path.name}\")\n",
    "    print(\"üîÑ Processing with load_gd_survey()...\")\n",
    "    \n",
    "    # The new function handles everything automatically!\n",
    "    survey_data = load_gd_survey(gd_path, gd_version=3, config=config)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Successfully loaded and processed GD3 data:\")\n",
    "    print(f\"   Participants: {len(survey_data):,}\")\n",
    "    print(f\"   Columns: {list(survey_data.columns)}\")\n",
    "    print(f\"\\nüìä Data sample:\")\n",
    "    print(survey_data.head())\n",
    "else:\n",
    "    print(\"‚ùå GD3 data file not found. Please ensure the global-dialogues submodule is initialized:\")\n",
    "    print(\"   git submodule update --init --recursive\")\n",
    "    survey_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore the Processed Survey Data\n",
    "\n",
    "Let's examine what `load_gd_survey()` did for us automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.301186Z",
     "iopub.status.busy": "2025-06-13T07:18:27.300963Z",
     "iopub.status.idle": "2025-06-13T07:18:27.333507Z",
     "shell.execute_reply": "2025-06-13T07:18:27.332519Z"
    }
   },
   "outputs": [],
   "source": [
    "if survey_data is not None:\n",
    "    print(\"üìä Survey Data Analysis:\\n\")\n",
    "    \n",
    "    # Demographic distributions\n",
    "    for col in ['country', 'gender', 'age_group', 'religion', 'environment', 'region', 'continent']:\n",
    "        if col in survey_data.columns:\n",
    "            print(f\"\\n{col.replace('_', ' ').title()} Distribution:\")\n",
    "            value_counts = survey_data[col].value_counts()\n",
    "            \n",
    "            # Show top values\n",
    "            show_n = 10 if col == 'country' else len(value_counts)\n",
    "            for value, count in value_counts.head(show_n).items():\n",
    "                print(f\"  {value}: {count} ({count/len(survey_data)*100:.1f}%)\")\n",
    "            \n",
    "            if col == 'country' and len(value_counts) > 10:\n",
    "                print(f\"  ... and {len(value_counts) - 10} more countries\")\n",
    "    \n",
    "    # Check which dimensions we can analyze\n",
    "    print(\"\\nüìã Analyzable GRI Dimensions:\")\n",
    "    for dimension in config.get_all_dimensions():\n",
    "        required_cols = dimension['columns']\n",
    "        if all(col in survey_data.columns for col in required_cols):\n",
    "            print(f\"  ‚úÖ {dimension['name']}\")\n",
    "        else:\n",
    "            missing = [col for col in required_cols if col not in survey_data.columns]\n",
    "            print(f\"  ‚ùå {dimension['name']} (missing: {missing})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.336774Z",
     "iopub.status.busy": "2025-06-13T07:18:27.336525Z",
     "iopub.status.idle": "2025-06-13T07:18:27.353311Z",
     "shell.execute_reply": "2025-06-13T07:18:27.352513Z"
    }
   },
   "outputs": [],
   "source": [
    "## 5. Validate Survey Data\n",
    "\n",
    "The `validate_survey_data()` function checks for data quality issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if survey_data is not None:\n",
    "    print(\"üîç Validating survey data...\\n\")\n",
    "    \n",
    "    # Validate with core demographic columns\n",
    "    required_cols = ['country', 'gender', 'age_group']\n",
    "    is_valid, issues = validate_survey_data(survey_data, required_columns=required_cols)\n",
    "    \n",
    "    if is_valid:\n",
    "        print(\"‚úÖ Survey data passed validation!\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Survey data has {len(issues)} issues:\")\n",
    "        for issue in issues:\n",
    "            print(f\"   - {issue}\")\n",
    "    \n",
    "    # Additional quality checks\n",
    "    print(\"\\nüìä Data Quality Metrics:\")\n",
    "    print(f\"   Total participants: {len(survey_data):,}\")\n",
    "    print(f\"   Complete records: {survey_data.notna().all(axis=1).sum():,}\")\n",
    "    print(f\"   Countries represented: {survey_data['country'].nunique()}\")\n",
    "    print(f\"   Gender categories: {survey_data['gender'].nunique()}\")\n",
    "    print(f\"   Age groups: {survey_data['age_group'].nunique()}\")\n",
    "    \n",
    "    # Check for non-binary gender representation\n",
    "    if 'gender' in survey_data.columns:\n",
    "        gender_counts = survey_data['gender'].value_counts()\n",
    "        non_binary_count = sum(count for gender, count in gender_counts.items() \n",
    "                              if gender not in ['Male', 'Female'])\n",
    "        if non_binary_count > 0:\n",
    "            print(f\"\\nüìù Note: {non_binary_count} participants with non-binary gender\")\n",
    "            print(\"   These will be excluded from gender-stratified GRI calculations\")\n",
    "            print(\"   (UN benchmark data only available for Male/Female)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.356456Z",
     "iopub.status.busy": "2025-06-13T07:18:27.356233Z",
     "iopub.status.idle": "2025-06-13T07:18:27.416407Z",
     "shell.execute_reply": "2025-06-13T07:18:27.415582Z"
    }
   },
   "outputs": [],
   "source": [
    "## 6. Check Alignment Between Survey and Benchmark Data\n",
    "\n",
    "Let's verify that the survey categories align with benchmark categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.420428Z",
     "iopub.status.busy": "2025-06-13T07:18:27.420009Z",
     "iopub.status.idle": "2025-06-13T07:18:27.427065Z",
     "shell.execute_reply": "2025-06-13T07:18:27.426517Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_category_alignment(survey_df, benchmark_df, columns):\n",
    "    \"\"\"Check how well survey categories align with benchmark categories.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in survey_df.columns and col in benchmark_df.columns:\n",
    "            survey_cats = set(survey_df[col].dropna().unique())\n",
    "            benchmark_cats = set(benchmark_df[col].dropna().unique())\n",
    "            \n",
    "            matched = survey_cats.intersection(benchmark_cats)\n",
    "            unmatched = survey_cats - benchmark_cats\n",
    "            \n",
    "            results[col] = {\n",
    "                'survey_count': len(survey_cats),\n",
    "                'benchmark_count': len(benchmark_cats),\n",
    "                'matched': len(matched),\n",
    "                'unmatched': list(unmatched),\n",
    "                'coverage': len(matched) / len(survey_cats) * 100 if survey_cats else 0\n",
    "            }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.430337Z",
     "iopub.status.busy": "2025-06-13T07:18:27.429927Z",
     "iopub.status.idle": "2025-06-13T07:18:27.453428Z",
     "shell.execute_reply": "2025-06-13T07:18:27.452865Z"
    }
   },
   "outputs": [],
   "source": [
    "if survey_data is not None:\n",
    "    print(\"üîç Checking alignment between survey and benchmark data...\\n\")\n",
    "    \n",
    "    # Check alignment for key dimensions\n",
    "    dimensions_to_check = [\n",
    "        ('Country √ó Gender √ó Age', ['country', 'gender', 'age_group']),\n",
    "        ('Country √ó Religion', ['country', 'religion']),\n",
    "        ('Country √ó Environment', ['country', 'environment'])\n",
    "    ]\n",
    "    \n",
    "    for dimension_name, columns in dimensions_to_check:\n",
    "        if dimension_name in benchmarks:\n",
    "            print(f\"\\nüìä {dimension_name} Alignment:\")\n",
    "            alignment = check_category_alignment(survey_data, benchmarks[dimension_name], columns)\n",
    "            \n",
    "            for col, stats in alignment.items():\n",
    "                print(f\"\\n   {col.replace('_', ' ').title()}:\")\n",
    "                print(f\"      Survey categories: {stats['survey_count']}\")\n",
    "                print(f\"      Matched with benchmark: {stats['matched']} ({stats['coverage']:.1f}%)\")\n",
    "                \n",
    "                if stats['unmatched']:\n",
    "                    print(f\"      Unmatched: {stats['unmatched'][:5]}\")\n",
    "                    if len(stats['unmatched']) > 5:\n",
    "                        print(f\"                 ... and {len(stats['unmatched']) - 5} more\")\n",
    "    \n",
    "    # Overall alignment summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä ALIGNMENT SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Key insights\n",
    "    if 'country' in survey_data.columns:\n",
    "        country_coverage = len(set(survey_data['country']) & set(benchmarks['Country']['country']))\n",
    "        print(f\"\\n‚úÖ Countries with full demographic data: {country_coverage}\")\n",
    "        \n",
    "    print(\"\\nüìù Notes:\")\n",
    "    print(\"- Some countries may lack religious composition data (Pew Research gaps)\")\n",
    "    print(\"- Some countries may lack urban/rural data (UN data gaps)\")\n",
    "    print(\"- Non-binary gender categories excluded (no UN benchmark available)\")\n",
    "    print(\"\\n‚úÖ Data is ready for GRI calculation across all supported dimensions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Survey Data\n",
    "\n",
    "Let's save the processed survey data for use in GRI calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T07:18:27.492631Z",
     "iopub.status.busy": "2025-06-13T07:18:27.492448Z",
     "iopub.status.idle": "2025-06-13T07:18:27.512324Z",
     "shell.execute_reply": "2025-06-13T07:18:27.511975Z"
    }
   },
   "outputs": [],
   "source": [
    "if survey_data is not None:\n",
    "    # Save the processed data\n",
    "    output_path = Path('../data/processed/gd3_survey_data_processed.csv')\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    survey_data.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(\"üíæ Saved processed survey data\")\n",
    "    print(f\"üìÅ Location: {output_path}\")\n",
    "    print(f\"üìä Size: {len(survey_data):,} participants √ó {len(survey_data.columns)} columns\")\n",
    "    \n",
    "    # Create a summary of what was processed\n",
    "    print(\"\\nüìã Processing Summary:\")\n",
    "    print(\"‚úÖ Applied segment mappings from config/segments.yaml\")\n",
    "    print(\"‚úÖ Added geographic hierarchies (region, continent)\")\n",
    "    print(\"‚úÖ Standardized column names\")\n",
    "    print(\"‚úÖ Validated data quality\")\n",
    "    print(\"‚úÖ Ready for GRI calculation!\")\n",
    "else:\n",
    "    print(\"‚ùå No survey data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the **new GRI module capabilities** for data preparation:\n",
    "\n",
    "### üéØ Key Features Used\n",
    "\n",
    "1. **`load_benchmark_suite()`** - Loaded all 13 benchmark dimensions at once\n",
    "2. **`load_gd_survey()`** - Automatically processed Global Dialogues data with:\n",
    "   - Format detection and handling\n",
    "   - Segment mapping application\n",
    "   - Geographic hierarchy addition\n",
    "   - Column standardization\n",
    "3. **`validate_benchmark_data()`** - Validated benchmark data quality\n",
    "4. **`validate_survey_data()`** - Checked survey data for issues\n",
    "\n",
    "### üìä Results\n",
    "\n",
    "- ‚úÖ Loaded complete benchmark suite covering all configured dimensions\n",
    "- ‚úÖ Processed Global Dialogues survey with {len(survey_data) if survey_data is not None else 0} participants\n",
    "- ‚úÖ Validated all data for quality and completeness\n",
    "- ‚úÖ Verified alignment between survey and benchmark categories\n",
    "- ‚úÖ Saved processed data ready for GRI calculation\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "1. **Calculate GRI scores** - Use `2-gri-calculation-example.ipynb`\n",
    "2. **Perform analysis** - Use `3-advanced-analysis.ipynb`\n",
    "3. **Command line** - Run `make calculate-gri GD=3`\n",
    "\n",
    "### üí° Benefits of the New Module Structure\n",
    "\n",
    "- **Less code** - Complex operations handled by module functions\n",
    "- **More reliable** - Consistent processing and validation\n",
    "- **Educational** - Clear separation of concerns\n",
    "- **Reusable** - Same functions work for any survey data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
