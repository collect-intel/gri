{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation for GRI Calculation\n",
    "\n",
    "This notebook demonstrates how to prepare data for Global Representativeness Index (GRI) calculations.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The GRI requires two types of data:\n",
    "1. **Benchmark data**: Global population demographics from UN and Pew Research\n",
    "2. **Survey data**: Participant demographics from your survey\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "First, ensure you have processed the benchmark data by running:\n",
    "```bash\n",
    "python scripts/process_data.py\n",
    "```\n",
    "\n",
    "This creates standardized benchmark files in `data/processed/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the gri module to the path\n",
    "sys.path.append('..')\n",
    "from gri.utils import load_data\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Processed Benchmark Data\n",
    "\n",
    "The benchmark data has been processed into three dimensions for the GRI Scorecard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed benchmark data\n",
    "benchmark_age_gender = load_data('../data/processed/benchmark_country_gender_age.csv')\n",
    "benchmark_religion = load_data('../data/processed/benchmark_country_religion.csv')\n",
    "benchmark_environment = load_data('../data/processed/benchmark_country_environment.csv')\n",
    "\n",
    "print(\"Benchmark Data Summary:\")\n",
    "print(f\"Country x Gender x Age: {len(benchmark_age_gender):,} strata\")\n",
    "print(f\"Country x Religion: {len(benchmark_religion):,} strata\")\n",
    "print(f\"Country x Environment: {len(benchmark_environment):,} strata\")\n",
    "\n",
    "# Verify proportions sum to 1.0\n",
    "print(\"\\nProportion sums (should be 1.0):\")\n",
    "print(f\"Age/Gender: {benchmark_age_gender['population_proportion'].sum():.6f}\")\n",
    "print(f\"Religion: {benchmark_religion['population_proportion'].sum():.6f}\")\n",
    "print(f\"Environment: {benchmark_environment['population_proportion'].sum():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview benchmark data structures\n",
    "print(\"Country x Gender x Age Benchmark:\")\n",
    "print(benchmark_age_gender.head())\n",
    "print(\"\\nUnique age groups:\", sorted(benchmark_age_gender['age_group'].unique()))\n",
    "print(\"Unique genders:\", sorted(benchmark_age_gender['gender'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Country x Religion Benchmark:\")\n",
    "print(benchmark_religion.head())\n",
    "print(\"\\nUnique religions:\", sorted(benchmark_religion['religion'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Country x Environment Benchmark:\")\n",
    "print(benchmark_environment.head())\n",
    "print(\"\\nUnique environments:\", sorted(benchmark_environment['environment'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Examine Survey Data\n",
    "\n",
    "Now let's load sample survey data from the Global Dialogues project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Global Dialogues participant data (GD4 as example)\n",
    "survey_path = '../data/raw/survey_data/global-dialogues/Data/GD4/GD4_participants.csv'\n",
    "\n",
    "if os.path.exists(survey_path):\n",
    "    # Load survey data - the file has some formatting issues, so we'll handle them\n",
    "    survey_raw = pd.read_csv(survey_path, skiprows=1)  # Skip the empty first row\n",
    "    \n",
    "    print(f\"Raw survey data shape: {survey_raw.shape}\")\n",
    "    print(\"\\nColumn names:\")\n",
    "    for i, col in enumerate(survey_raw.columns[:10]):  # Show first 10 columns\n",
    "        print(f\"{i}: {col}\")\nelse:\n",
    "    print(f\"Survey file not found at {survey_path}\")\n",
    "    print(\"Note: Global Dialogues data is in a Git submodule.\")\n",
    "    print(\"You may need to initialize the submodule or use your own survey data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean and Standardize Survey Data\n",
    "\n",
    "For GRI calculation, we need to map survey demographics to match the benchmark categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample survey data if the real data isn't available\n",
    "if 'survey_raw' not in locals() or survey_raw.empty:\n",
    "    print(\"Creating sample survey data for demonstration...\")\n",
    "    \n",
    "    # Create realistic sample data\n",
    "    np.random.seed(42)\n",
    "    n_participants = 500\n",
    "    \n",
    "    sample_countries = ['United States', 'India', 'Brazil', 'Germany', 'Nigeria', 'Japan']\n",
    "    sample_ages = ['18-25', '26-35', '36-45', '46-55', '56-65', '65+']\n",
    "    sample_genders = ['Male', 'Female']\n",
    "    sample_religions = ['Christianity', 'Islam', 'Hinduism', 'Buddhism', 'Judaism', \n",
    "                       'I do not identify with any religious group or faith', 'Other religious group']\n",
    "    sample_environments = ['Urban', 'Rural']\n",
    "    \n",
    "    survey_data = pd.DataFrame({\n",
    "        'country': np.random.choice(sample_countries, n_participants),\n",
    "        'age_group': np.random.choice(sample_ages, n_participants),\n",
    "        'gender': np.random.choice(sample_genders, n_participants),\n",
    "        'religion': np.random.choice(sample_religions, n_participants),\n",
    "        'environment': np.random.choice(sample_environments, n_participants)\n",
    "    })\n",
    "    \n",
    "    print(f\"Sample survey data created with {len(survey_data)} participants\")\n",
    "    \n",
    "else:\n",
    "    print(\"Processing real Global Dialogues data...\")\n",
    "    \n",
    "    # Extract relevant demographic columns from Global Dialogues data\n",
    "    # Note: Column names may vary - adjust as needed based on actual data structure\n",
    "    survey_data = pd.DataFrame()\n",
    "    \n",
    "    # Map country column (column index varies)\n",
    "    country_col = None\n",
    "    for col in survey_raw.columns:\n",
    "        if 'country' in str(col).lower() or 'region' in str(col).lower():\n",
    "            country_col = col\n",
    "            break\n",
    "    \n",
    "    if country_col:\n",
    "        survey_data['country'] = survey_raw[country_col]\n",
    "    \n",
    "    # Add other demographic mappings as needed...\n",
    "    print(\"Real data processing would require specific column mapping\")\n",
    "    print(\"Using sample data for this demonstration...\")\n",
    "    \n",
    "    # Fall back to sample data for demo\n",
    "    np.random.seed(42)\n",
    "    n_participants = 500\n",
    "    \n",
    "    sample_countries = ['United States', 'India', 'Brazil', 'Germany', 'Nigeria', 'Japan']\n",
    "    sample_ages = ['18-25', '26-35', '36-45', '46-55', '56-65', '65+']\n",
    "    sample_genders = ['Male', 'Female']\n",
    "    sample_religions = ['Christianity', 'Islam', 'Hinduism', 'Buddhism', 'Judaism', \n",
    "                       'I do not identify with any religious group or faith', 'Other religious group']\n",
    "    sample_environments = ['Urban', 'Rural']\n",
    "    \n",
    "    survey_data = pd.DataFrame({\n",
    "        'country': np.random.choice(sample_countries, n_participants),\n",
    "        'age_group': np.random.choice(sample_ages, n_participants),\n",
    "        'gender': np.random.choice(sample_genders, n_participants),\n",
    "        'religion': np.random.choice(sample_religions, n_participants),\n",
    "        'environment': np.random.choice(sample_environments, n_participants)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display survey data summary\n",
    "print(\"Survey Data Summary:\")\n",
    "print(f\"Total participants: {len(survey_data)}\")\n",
    "print(\"\\nCountry distribution:\")\n",
    "print(survey_data['country'].value_counts())\n",
    "\n",
    "print(\"\\nAge group distribution:\")\n",
    "print(survey_data['age_group'].value_counts())\n",
    "\n",
    "print(\"\\nGender distribution:\")\n",
    "print(survey_data['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Validation and Alignment\n",
    "\n",
    "Before calculating GRI, we need to ensure the survey categories align with benchmark categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check alignment between survey and benchmark categories\n",
    "def check_category_alignment(survey_df, benchmark_df, columns):\n",
    "    \"\"\"Check which survey categories are present in benchmark data.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in survey_df.columns and col in benchmark_df.columns:\n",
    "            survey_cats = set(survey_df[col].unique())\n",
    "            benchmark_cats = set(benchmark_df[col].unique())\n",
    "            \n",
    "            matched = survey_cats.intersection(benchmark_cats)\n",
    "            unmatched = survey_cats - benchmark_cats\n",
    "            \n",
    "            results[col] = {\n",
    "                'total_survey': len(survey_cats),\n",
    "                'matched': len(matched),\n",
    "                'unmatched': unmatched\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Check age/gender alignment\n",
    "age_gender_alignment = check_category_alignment(\n",
    "    survey_data, benchmark_age_gender, ['country', 'gender', 'age_group']\n",
    ")\n",
    "\n",
    "print(\"Age/Gender Category Alignment:\")\n",
    "for col, stats in age_gender_alignment.items():\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Survey categories: {stats['total_survey']}\")\n",
    "    print(f\"  Matched with benchmark: {stats['matched']}\")\n",
    "    if stats['unmatched']:\n",
    "        print(f\"  Unmatched: {stats['unmatched']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check religion alignment\n",
    "religion_alignment = check_category_alignment(\n",
    "    survey_data, benchmark_religion, ['country', 'religion']\n",
    ")\n",
    "\n",
    "print(\"Religion Category Alignment:\")\n",
    "for col, stats in religion_alignment.items():\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Survey categories: {stats['total_survey']}\")\n",
    "    print(f\"  Matched with benchmark: {stats['matched']}\")\n",
    "    if stats['unmatched']:\n",
    "        print(f\"  Unmatched: {stats['unmatched']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check environment alignment\n",
    "environment_alignment = check_category_alignment(\n",
    "    survey_data, benchmark_environment, ['country', 'environment']\n",
    ")\n",
    "\n",
    "print(\"Environment Category Alignment:\")\n",
    "for col, stats in environment_alignment.items():\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Survey categories: {stats['total_survey']}\")\n",
    "    print(f\"  Matched with benchmark: {stats['matched']}\")\n",
    "    if stats['unmatched']:\n",
    "        print(f\"  Unmatched: {stats['unmatched']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Country Name Standardization\n",
    "\n",
    "Country names often need to be standardized between survey and benchmark data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of countries in benchmark vs survey\n",
    "print(\"Sample benchmark countries:\")\n",
    "print(sorted(benchmark_age_gender['country'].unique())[:10])\n",
    "\n",
    "print(\"\\nSurvey countries:\")\n",
    "print(sorted(survey_data['country'].unique()))\n",
    "\n",
    "# Create country mapping if needed\n",
    "country_mapping = {\n",
    "    'United States': 'United States of America',\n",
    "    'Germany': 'Germany',\n",
    "    'Brazil': 'Brazil',\n",
    "    'India': 'India',\n",
    "    'Nigeria': 'Nigeria',\n",
    "    'Japan': 'Japan'\n",
    "}\n",
    "\n",
    "# Apply country mapping\n",
    "survey_data_clean = survey_data.copy()\n",
    "survey_data_clean['country'] = survey_data_clean['country'].map(country_mapping).fillna(survey_data_clean['country'])\n",
    "\n",
    "print(\"\\nAfter mapping:\")\n",
    "print(survey_data_clean['country'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Cleaned Survey Data\n",
    "\n",
    "Save the cleaned survey data for use in GRI calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned survey data\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "survey_data_clean.to_csv('../data/processed/sample_survey_data.csv', index=False)\n",
    "\n",
    "print(\"Cleaned survey data saved to: data/processed/sample_survey_data.csv\")\n",
    "print(f\"Final dataset shape: {survey_data_clean.shape}\")\n",
    "print(\"\\nData is now ready for GRI calculation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. ✅ Loaded processed benchmark data for all three GRI dimensions\n",
    "2. ✅ Loaded and examined survey data structure\n",
    "3. ✅ Cleaned and standardized survey demographics\n",
    "4. ✅ Validated category alignment between survey and benchmark\n",
    "5. ✅ Applied country name standardization\n",
    "6. ✅ Saved cleaned data for GRI calculation\n",
    "\n",
    "**Next Steps:**\n",
    "- Proceed to `2-gri-calculation-example.ipynb` to calculate GRI scores\n",
    "- Use `3-advanced-analysis.ipynb` for detailed representativeness analysis\n",
    "\n",
    "**Key Files Created:**\n",
    "- `data/processed/sample_survey_data.csv` - Cleaned survey data ready for GRI calculation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}