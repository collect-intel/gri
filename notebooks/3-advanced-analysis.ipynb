{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 3. Advanced GRI Analysis\n\nThis notebook demonstrates advanced analysis techniques using the GRI module's comprehensive features:\n- Monte Carlo simulations to understand achievable GRI scores\n- Comprehensive reporting and visualization capabilities\n- Alignment checking and segment-level analysis\n- Survey comparison tools\n- Sample size analysis and optimization\n\n## Overview\n\nThe GRI module provides powerful tools to:\n1. **Simulate maximum achievable GRI scores** given real-world constraints\n2. **Identify specific over/under-represented groups** with detailed segment analysis\n3. **Compare multiple surveys** to track progress over time\n4. **Generate comprehensive reports** with actionable insights\n5. **Optimize sample sizes** for different representativeness targets"
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T01:21:58.587450Z",
     "iopub.status.busy": "2025-06-14T01:21:58.587220Z",
     "iopub.status.idle": "2025-06-14T01:21:58.993240Z",
     "shell.execute_reply": "2025-06-14T01:21:58.992952Z"
    }
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom typing import Dict, List\nimport json\nfrom pathlib import Path\n\n# Import the GRI module components\nfrom gri import GRIAnalysis\nfrom gri.simulation import monte_carlo_max_scores, generate_sample_size_curve\nfrom gri.reports import generate_comparison_report\nfrom gri.visualization import create_comparison_plot\n\n# Set plotting style\nplt.style.use('default')\nsns.set_palette('RdYlBu_r')\n\n# Set pandas display options\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_rows', 20)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Initialize GRI Analysis\n\nThe GRIAnalysis class provides a comprehensive interface for all GRI calculations and analysis."
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T01:21:58.994758Z",
     "iopub.status.busy": "2025-06-14T01:21:58.994636Z",
     "iopub.status.idle": "2025-06-14T01:21:59.003408Z",
     "shell.execute_reply": "2025-06-14T01:21:59.003149Z"
    }
   },
   "outputs": [],
   "source": "# Initialize GRI analysis for multiple surveys\nsurveys = {}\nfor survey_name in ['GD1', 'GD2', 'GD3']:\n    try:\n        # Create GRIAnalysis instance\n        filepath = f'../data/processed/{survey_name.lower()}_demographics.csv'\n        if Path(filepath).exists():\n            survey_data = pd.read_csv(filepath)\n            analysis = GRIAnalysis(survey_data=survey_data, survey_name=survey_name)\n        else:\n            raise FileNotFoundError(f\"Survey file not found: {filepath}\")\n        \n        # Calculate GRI scores\n        scorecard = analysis.calculate_scorecard(include_max_possible=True)\n        \n        # Extract results in expected format\n        results = {\n            'average_gri': scorecard['gri_score'].mean()\n        }\n        \n        # Add dimension-specific scores\n        for _, row in scorecard.iterrows():\n            dim_key = 'gri_' + row['dimension'].lower().replace(' √ó ', '_').replace(' ', '_')\n            results[dim_key] = row['gri_score']\n        \n        surveys[survey_name] = {\n            'analysis': analysis,\n            'results': results,\n            'scorecard': scorecard,\n            'n_participants': len(analysis.survey_data)\n        }\n        \n        print(f\"{survey_name}:\")\n        print(f\"  Participants: {surveys[survey_name]['n_participants']}\")\n        print(f\"  Overall GRI: {results['average_gri']:.4f}\")\n        \n        # Print specific dimensions if they exist\n        for dim in ['country_gender_age', 'country_religion', 'country_environment']:\n            key = f'gri_{dim}'\n            if key in results:\n                print(f\"    - {dim.replace('_', '√ó').title()}: {results[key]:.4f}\")\n        print()\n        \n    except FileNotFoundError as e:\n        print(f\"{survey_name}: {e}\")\n        print()\n    except Exception as e:\n        print(f\"{survey_name}: Error - {type(e).__name__}: {e}\")\n        print()\n\n# Select primary survey for detailed analysis\nprimary_survey = 'GD3'\nif primary_survey in surveys:\n    analysis = surveys[primary_survey]['analysis']\n    results = surveys[primary_survey]['results']\n    scorecard = surveys[primary_survey]['scorecard']\n    print(f\"Selected {primary_survey} for detailed analysis\")\nelse:\n    print(f\"Warning: {primary_survey} not found in surveys\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T01:21:59.019753Z",
     "iopub.status.busy": "2025-06-14T01:21:59.019631Z",
     "iopub.status.idle": "2025-06-14T01:21:59.950733Z",
     "shell.execute_reply": "2025-06-14T01:21:59.949656Z"
    }
   },
   "source": "## 2. Monte Carlo Simulation: Understanding Achievable GRI Scores\n\nOne key question is: \"What's the maximum GRI score we could achieve given real-world constraints?\"\n\nThe monte_carlo_max_scores function simulates thousands of possible samples to find the theoretical maximum."
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T01:21:59.954102Z",
     "iopub.status.busy": "2025-06-14T01:21:59.953746Z",
     "iopub.status.idle": "2025-06-14T01:21:59.960106Z",
     "shell.execute_reply": "2025-06-14T01:21:59.959606Z"
    }
   },
   "outputs": [],
   "source": "# Run Monte Carlo simulation to find maximum achievable GRI scores\nif 'analysis' in locals():\n    print(\"Running Monte Carlo simulation (this may take a moment)...\")\n    \n    # We need to run simulations for each dimension\n    simulation_results = {}\n    max_scores_by_dimension = {}\n    \n    # Get benchmark data for main dimensions\n    dimensions = {\n        'Country √ó Gender √ó Age': ['country', 'gender', 'age_group'],\n        'Country √ó Religion': ['country', 'religion'],\n        'Country √ó Environment': ['country', 'environment']\n    }\n    \n    for dim_name, dim_cols in dimensions.items():\n        if dim_name in analysis.benchmarks:\n            benchmark_df = analysis.benchmarks[dim_name]\n            \n            # Run simulation for this dimension\n            sim_result = monte_carlo_max_scores(\n                benchmark_df=benchmark_df,\n                sample_size=len(analysis.survey_data),\n                dimension_columns=dim_cols,\n                n_simulations=1000\n            )\n            \n            max_scores_by_dimension[dim_name] = sim_result['max_gri']\n    \n    # Calculate overall results\n    max_average_gri = np.mean(list(max_scores_by_dimension.values()))\n    \n    print(\"\\nüéØ MONTE CARLO SIMULATION RESULTS\")\n    print(\"=\" * 60)\n    print(f\"Sample size: {len(analysis.survey_data)} participants\")\n    print(f\"Simulations run: 1000 per dimension\")\n    print(f\"\\nActual {primary_survey} GRI: {results['average_gri']:.4f}\")\n    print(f\"Theoretical maximum GRI (average): {max_average_gri:.4f}\")\n    print(f\"Gap to maximum: {max_average_gri - results['average_gri']:.4f}\")\n    \n    # Show dimension-specific results\n    print(\"\\nDimension-specific maximum scores:\")\n    for dim_name, max_score in max_scores_by_dimension.items():\n        # Find actual score for this dimension\n        actual = scorecard[scorecard['dimension'] == dim_name]['gri_score'].values[0] if dim_name in scorecard['dimension'].values else 0\n        print(f\"  {dim_name}: max={max_score:.4f}, actual={actual:.4f}, gap={max_score-actual:.4f}\")\n    \n    # Visualize the results\n    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n    \n    # Compare actual vs maximum by dimension\n    dimensions = list(max_scores_by_dimension.keys())\n    actual_scores = []\n    for dim in dimensions:\n        if dim in scorecard['dimension'].values:\n            actual_scores.append(scorecard[scorecard['dimension'] == dim]['gri_score'].values[0])\n        else:\n            actual_scores.append(0)\n    \n    max_scores = list(max_scores_by_dimension.values())\n    \n    x = np.arange(len(dimensions))\n    width = 0.35\n    \n    ax.bar(x - width/2, actual_scores, width, label='Actual', alpha=0.8)\n    ax.bar(x + width/2, max_scores, width, label='Maximum', alpha=0.8)\n    ax.set_xlabel('Dimension')\n    ax.set_ylabel('GRI Score')\n    ax.set_title(f'{primary_survey} - Actual vs Maximum GRI by Dimension')\n    ax.set_xticks(x)\n    ax.set_xticklabels([d.replace(' √ó ', '\\n') for d in dimensions], rotation=0)\n    ax.legend()\n    ax.set_ylim(0, 1)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nüí° Insight: The {primary_survey} survey has room for improvement across all dimensions.\")\nelse:\n    print(\"‚ö†Ô∏è No analysis object available. Please run the previous cells to load survey data.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T01:21:59.963290Z",
     "iopub.status.busy": "2025-06-14T01:21:59.963128Z",
     "iopub.status.idle": "2025-06-14T01:22:00.216314Z",
     "shell.execute_reply": "2025-06-14T01:22:00.216051Z"
    }
   },
   "source": "## 3. Segment Analysis: Identifying Key Representativeness Gaps\n\nThe GRIAnalysis class provides powerful segment analysis to identify which specific demographic groups drive representativeness gaps."
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T01:22:00.218048Z",
     "iopub.status.busy": "2025-06-14T01:22:00.217941Z",
     "iopub.status.idle": "2025-06-14T01:22:00.224399Z",
     "shell.execute_reply": "2025-06-14T01:22:00.223814Z"
    }
   },
   "outputs": [],
   "source": "# Get top contributing segments for all dimensions\nif 'analysis' in locals():\n    print(\"TOP 10 SEGMENTS CONTRIBUTING TO GRI DEVIATION\")\n    print(\"=\" * 80)\n    \n    # Collect top segments from each dimension\n    all_segments = []\n    for dim_name in ['Country √ó Gender √ó Age', 'Country √ó Religion', 'Country √ó Environment']:\n        if dim_name in scorecard['dimension'].values:\n            try:\n                segments = analysis.get_top_segments(dim_name, n=20)\n                if not segments.empty:\n                    all_segments.append(segments)\n            except Exception as e:\n                print(f\"Could not get segments for {dim_name}: {e}\")\n    \n    if all_segments:\n        # Combine and sort by absolute deviation\n        top_segments = pd.concat(all_segments).sort_values('abs_deviation', ascending=False).head(20)\n        \n        # Display top 10\n        for i, (idx, segment) in enumerate(top_segments.head(10).iterrows(), 1):\n            print(f\"{i:2d}. Dimension: {segment.get('dimension', 'Unknown')}\")\n            \n            # Build segment description based on available columns\n            segment_parts = []\n            for col in ['country', 'gender', 'age_group', 'religion', 'environment']:\n                if col in segment and pd.notna(segment[col]):\n                    segment_parts.append(f\"{col.title()}: {segment[col]}\")\n            \n            if segment_parts:\n                print(f\"    Segment: {', '.join(segment_parts)}\")\n            \n            print(f\"    Deviation: {segment.get('deviation', 0):+.2%} from expected\")\n            print(f\"    Sample: {segment.get('sample_proportion', 0):.2%}, Expected: {segment.get('benchmark_proportion', 0):.2%}\")\n            \n            if segment.get('deviation', 0) > 0:\n                print(f\"    Status: Over-represented\")\n            else:\n                print(f\"    Status: Under-represented\")\n            print()\n        \n        # Visualize segment deviations\n        analysis.plot_top_deviations('Country √ó Gender √ó Age', n=15)\n    else:\n        print(\"No segment data available\")\n    \n    # Generate recommendations based on deviations\n    print(\"\\nüéØ ACTIONABLE RECOMMENDATIONS\")\n    print(\"=\" * 80)\n    \n    if all_segments:\n        # Find most under-represented segments\n        under_represented = top_segments[top_segments['deviation'] < 0].head(5)\n        if not under_represented.empty:\n            print(\"\\nFOCUS RECRUITMENT ON:\")\n            for _, seg in under_represented.iterrows():\n                segment_desc = []\n                for col in ['country', 'gender', 'age_group', 'religion', 'environment']:\n                    if col in seg and pd.notna(seg[col]):\n                        segment_desc.append(seg[col])\n                print(f\"  ‚Ä¢ {' - '.join(segment_desc)}: Need {abs(seg['deviation']):.1%} more representation\")\n        \n        # Find most over-represented segments\n        over_represented = top_segments[top_segments['deviation'] > 0].head(5)\n        if not over_represented.empty:\n            print(\"\\nCONSIDER REDUCING:\")\n            for _, seg in over_represented.iterrows():\n                segment_desc = []\n                for col in ['country', 'gender', 'age_group', 'religion', 'environment']:\n                    if col in seg and pd.notna(seg[col]):\n                        segment_desc.append(seg[col])\n                print(f\"  ‚Ä¢ {' - '.join(segment_desc)}: {seg['deviation']:.1%} over-represented\")\nelse:\n    print(\"‚ö†Ô∏è No analysis object available. Please run the previous cells to load survey data.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Sample Size Analysis: How Many Participants Do We Need?\n\nUnderstanding the relationship between sample size and achievable GRI scores helps in planning future surveys."
  },
  {
   "cell_type": "code",
   "source": "# Generate sample size curve for a key dimension\nif 'analysis' in locals():\n    print(\"Analyzing sample size vs achievable GRI...\")\n    \n    # Use Country √ó Gender √ó Age as the main dimension for analysis\n    main_dimension = 'Country √ó Gender √ó Age'\n    if main_dimension in analysis.benchmarks:\n        benchmark_df = analysis.benchmarks[main_dimension]\n        \n        sample_sizes = [100, 250, 500, 750, 1000, 1500, 2000, 3000, 5000]\n        sample_size_df = generate_sample_size_curve(\n            benchmark_df=benchmark_df,\n            sample_sizes=sample_sizes,\n            dimension_columns=['country', 'gender', 'age_group'],\n            n_simulations=100\n        )\n        \n        # Get current actual GRI for this dimension\n        current_gri = scorecard[scorecard['dimension'] == main_dimension]['gri_score'].values[0]\n        \n        # Visualize the results\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n        \n        # Plot max GRI vs sample size\n        ax1.plot(sample_size_df['sample_size'], \n                 sample_size_df['max_gri'], \n                 'o-', label='Maximum Achievable GRI', linewidth=2, markersize=8)\n        ax1.axhline(y=current_gri, color='red', linestyle='--', \n                    label=f'Current {primary_survey} GRI')\n        ax1.axhline(y=0.7, color='green', linestyle=':', alpha=0.7,\n                    label='Target GRI (0.7)')\n        ax1.set_xlabel('Sample Size')\n        ax1.set_ylabel('GRI Score')\n        ax1.set_title(f'Maximum Achievable GRI vs Sample Size\\n({main_dimension})')\n        ax1.legend()\n        ax1.grid(True, alpha=0.3)\n        ax1.set_xscale('log')\n        \n        # Plot diversity scores\n        if 'max_diversity' in sample_size_df.columns:\n            ax2.plot(sample_size_df['sample_size'],\n                     sample_size_df['max_diversity'],\n                     's-', label='Maximum Diversity Score', linewidth=2)\n            ax2.set_xlabel('Sample Size')\n            ax2.set_ylabel('Diversity Score')\n            ax2.set_title('Maximum Achievable Diversity vs Sample Size')\n            ax2.legend()\n            ax2.grid(True, alpha=0.3)\n            ax2.set_xscale('log')\n        else:\n            # Alternative visualization: improvement potential\n            improvement = sample_size_df['max_gri'] - current_gri\n            ax2.plot(sample_size_df['sample_size'], improvement, 'o-', linewidth=2, markersize=8)\n            ax2.set_xlabel('Sample Size')\n            ax2.set_ylabel('Potential GRI Improvement')\n            ax2.set_title('Potential Improvement vs Sample Size')\n            ax2.grid(True, alpha=0.3)\n            ax2.set_xscale('log')\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Find optimal sample size for target GRI\n        target_gri = 0.7\n        optimal_size = None\n        for idx, row in sample_size_df.iterrows():\n            if row['max_gri'] >= target_gri:\n                optimal_size = row['sample_size']\n                break\n        \n        print(f\"\\nüí° SAMPLE SIZE INSIGHTS:\")\n        print(f\"  ‚Ä¢ Current sample size: {len(analysis.survey_data)}\")\n        print(f\"  ‚Ä¢ Current GRI: {current_gri:.4f}\")\n        if optimal_size:\n            print(f\"  ‚Ä¢ Minimum sample size for GRI ‚â• {target_gri}: ~{optimal_size:,} participants\")\n        else:\n            max_achievable = sample_size_df['max_gri'].max()\n            print(f\"  ‚Ä¢ Maximum achievable GRI with {max(sample_sizes):,} participants: {max_achievable:.4f}\")\n            if max_achievable < target_gri:\n                print(f\"  ‚Ä¢ Target GRI of {target_gri} may not be achievable for this dimension\")\n        \n        # Find point of diminishing returns\n        if len(sample_size_df) > 1:\n            improvements = sample_size_df['max_gri'].diff()\n            # Find where improvement drops below 0.01 per doubling\n            for i in range(1, len(improvements)):\n                if improvements.iloc[i] < 0.01:\n                    print(f\"  ‚Ä¢ Diminishing returns appear after ~{sample_size_df.iloc[i-1]['sample_size']:,} participants\")\n                    break\n    else:\n        print(f\"‚ö†Ô∏è Benchmark data for {main_dimension} not available\")\nelse:\n    print(\"‚ö†Ô∏è No analysis object available. Please run the previous cells to load survey data.\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Survey Comparison: Tracking Progress Over Time\n\nCompare multiple surveys to understand trends and improvements in representativeness.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Compare all available surveys\nif len(surveys) > 1:\n    # Prepare data for comparison\n    scorecards = []\n    survey_names = []\n    \n    for name, data in surveys.items():\n        scorecards.append(data['scorecard'])\n        survey_names.append(name)\n    \n    # Create comparison visualization\n    try:\n        fig = create_comparison_plot(\n            scorecards=scorecards,\n            survey_names=survey_names,\n            plot_type='both'  # Shows both radar and bar charts\n        )\n        plt.show()\n    except Exception as e:\n        print(f\"Could not create comparison plot: {e}\")\n    \n    # Generate comparison summary\n    print(\"\\nüìä SURVEY COMPARISON REPORT\")\n    print(\"=\" * 80)\n    \n    # Compare average GRI scores\n    for name, data in surveys.items():\n        print(f\"\\n{name}:\")\n        print(f\"  Participants: {data['n_participants']:,}\")\n        print(f\"  Average GRI: {data['results']['average_gri']:.4f}\")\n        \n        # Show dimension scores\n        for _, row in data['scorecard'].iterrows():\n            print(f\"    {row['dimension']}: {row['gri_score']:.4f}\")\n    \n    # Identify best practices from highest-scoring survey\n    best_survey = max(surveys.items(), key=lambda x: x[1]['results']['average_gri'])\n    print(f\"\\nüèÜ Best performing survey: {best_survey[0]} (GRI: {best_survey[1]['results']['average_gri']:.4f})\")\n    \n    # Show improvements over time\n    if 'GD1' in surveys and 'GD3' in surveys:\n        gd1_gri = surveys['GD1']['results']['average_gri']\n        gd3_gri = surveys['GD3']['results']['average_gri']\n        improvement = gd3_gri - gd1_gri\n        print(f\"\\nüìà Progress from GD1 to GD3: {improvement:+.4f} GRI points ({improvement/gd1_gri*100:+.1f}%)\")\n        \n        # Dimension-specific improvements\n        print(\"\\nDimension-specific improvements:\")\n        gd1_scorecard = surveys['GD1']['scorecard']\n        gd3_scorecard = surveys['GD3']['scorecard']\n        \n        for dim in gd3_scorecard['dimension'].unique():\n            if dim in gd1_scorecard['dimension'].values:\n                gd1_score = gd1_scorecard[gd1_scorecard['dimension'] == dim]['gri_score'].values[0]\n                gd3_score = gd3_scorecard[gd3_scorecard['dimension'] == dim]['gri_score'].values[0]\n                change = gd3_score - gd1_score\n                print(f\"  {dim}: {change:+.4f} ({change/gd1_score*100:+.1f}%)\")\nelse:\n    print(\"Only one survey available. Load multiple surveys to see comparisons.\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Alignment Analysis: Understanding Representation Patterns\n\nCheck how well the survey aligns with global population across different demographic cuts.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Check alignment across different demographic cuts\nalignment_report = analysis.check_alignment()\n\nprint(\"ALIGNMENT ANALYSIS\")\nprint(\"=\" * 80)\nprint(f\"Checking how well survey categories align with benchmark data...\\n\")\n\n# Summarize alignment by dimension\ntotal_coverage = []\nfor dimension, stats in alignment_report.items():\n    if stats['status'] == 'complete':\n        print(f\"{dimension}:\")\n        print(f\"  Overall alignment: {stats['overall_alignment']:.1%}\")\n        \n        total_coverage.append(stats['overall_alignment'])\n        \n        # Show any issues\n        if stats['issues']:\n            print(\"  Issues found:\")\n            for issue in stats['issues'][:3]:  # Show top 3 issues\n                print(f\"    ‚Ä¢ {issue['column']}: {issue['coverage']:.1%} coverage\")\n                if issue['unmatched_sample']:\n                    print(f\"      Missing: {', '.join(issue['unmatched_sample'][:3])}...\")\n        else:\n            print(\"  ‚úì Perfect alignment\")\n        print()\n    else:\n        print(f\"{dimension}: {stats.get('reason', 'Unknown issue')}\")\n        print()\n\n# Visualize alignment patterns for main dimensions\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\nmain_dimensions = ['Country √ó Gender √ó Age', 'Country √ó Religion', 'Country √ó Environment']\n\nfor idx, (dimension, ax) in enumerate(zip(main_dimensions, axes)):\n    if dimension in analysis.benchmarks:\n        # Get top deviations for this dimension\n        try:\n            segments = analysis.get_top_segments(dimension, n=15)\n            \n            if not segments.empty:\n                # Sort by deviation for better visualization\n                segments_sorted = segments.sort_values('deviation')\n                \n                # Plot horizontal bars\n                y_pos = range(len(segments_sorted))\n                bars = ax.barh(y_pos, segments_sorted['deviation'])\n                \n                # Color bars based on over/under representation\n                colors = ['red' if d < 0 else 'green' for d in segments_sorted['deviation']]\n                for bar, color in zip(bars, colors):\n                    bar.set_color(color)\n                \n                # Customize plot\n                ax.set_yticks(y_pos)\n                \n                # Create segment labels\n                labels = []\n                for _, seg in segments_sorted.iterrows():\n                    label_parts = []\n                    for col in ['country', 'gender', 'age_group', 'religion', 'environment']:\n                        if col in seg and pd.notna(seg[col]):\n                            label_parts.append(str(seg[col]))\n                    label = ' - '.join(label_parts[:2])  # Show first 2 parts\n                    if len(label) > 20:\n                        label = label[:17] + '...'\n                    labels.append(label)\n                \n                ax.set_yticklabels(labels, fontsize=8)\n                ax.axvline(x=0, color='black', linewidth=0.8)\n                ax.set_xlabel('Deviation from Expected (%)')\n                ax.set_title(dimension.replace(' √ó ', '\\n'))\n                ax.grid(True, alpha=0.3)\n        except Exception as e:\n            ax.text(0.5, 0.5, f'No data\\n({str(e)[:30]}...)', \n                   ha='center', va='center', transform=ax.transAxes)\n\nplt.tight_layout()\nplt.show()\n\n# Overall alignment score\nif total_coverage:\n    overall_alignment = np.mean(total_coverage) * 100\n    print(f\"\\nüìä OVERALL ALIGNMENT SCORE: {overall_alignment:.1f}%\")\n    print(f\"   Average coverage across {len(total_coverage)} dimensions\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Generate Comprehensive Report\n\nThe GRI module can generate detailed reports in multiple formats for sharing with stakeholders.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Generate and save comprehensive report\noutput_dir = Path('../analysis_output')\noutput_dir.mkdir(exist_ok=True)\n\n# Export analysis results\ntry:\n    analysis.export(format='json', filepath=str(output_dir / f'{primary_survey.lower()}_analysis.json'))\n    print(f\"‚úÖ Analysis results exported\")\nexcept Exception as e:\n    print(f\"Could not export results: {e}\")\n\n# Save key results for future use\nresults_summary = {\n    'survey': primary_survey,\n    'n_participants': len(analysis.survey_data),\n    'gri_scores': results,\n    'top_segments': all_segments[0].head(20).to_dict('records') if 'all_segments' in locals() and all_segments else [],\n    'max_scores_by_dimension': max_scores_by_dimension if 'max_scores_by_dimension' in locals() else {},\n    'alignment_score': overall_alignment if 'overall_alignment' in locals() else None\n}\n\noutput_file = output_dir / f'{primary_survey.lower()}_advanced_analysis.json'\nwith open(output_file, 'w') as f:\n    json.dump(results_summary, f, indent=2, default=str)\n\nprint(f\"‚úÖ Analysis summary saved: {output_file}\")\n\n# Display summary dashboard\nprint(\"\\n\" + \"=\"*80)\nprint(f\"ADVANCED ANALYSIS SUMMARY - {primary_survey}\")\nprint(\"=\"*80)\nprint(f\"Overall GRI Score: {results['average_gri']:.4f}\")\n\nif 'max_average_gri' in locals():\n    print(f\"Maximum Achievable GRI: {max_average_gri:.4f}\")\n    print(f\"Gap to Maximum: {max_average_gri - results['average_gri']:.4f}\")\n\nif 'overall_alignment' in locals():\n    print(f\"Alignment Score: {overall_alignment:.1f}%\")\n\nprint(\"\\nüéØ Key Insights:\")\nprint(f\"  ‚Ä¢ Survey has {len(analysis.survey_data):,} participants from {analysis.survey_data['country'].nunique()} countries\")\n\nif 'all_segments' in locals() and all_segments:\n    top_segment = all_segments[0].iloc[0]\n    print(f\"  ‚Ä¢ Largest deviation: \", end=\"\")\n    seg_desc = []\n    for col in ['country', 'gender', 'age_group', 'religion', 'environment']:\n        if col in top_segment and pd.notna(top_segment[col]):\n            seg_desc.append(str(top_segment[col]))\n    print(f\"{' - '.join(seg_desc)} ({top_segment['deviation']:+.1%})\")\n\nif 'optimal_size' in locals() and optimal_size:\n    print(f\"  ‚Ä¢ Recommended sample size for GRI ‚â• 0.7: {optimal_size:,} participants\")\n\n# Generate actionable recommendations\nprint(\"\\nüéØ Top 3 Actions:\")\nrecommendations = []\n\nif 'all_segments' in locals() and all_segments:\n    under_rep = all_segments[0][all_segments[0]['deviation'] < 0].head(3)\n    for i, (_, seg) in enumerate(under_rep.iterrows(), 1):\n        seg_desc = []\n        for col in ['country', 'gender', 'age_group', 'religion', 'environment']:\n            if col in seg and pd.notna(seg[col]):\n                seg_desc.append(str(seg[col]))\n        print(f\"  {i}. Recruit more: {' - '.join(seg_desc)} (need {abs(seg['deviation']):.1%} more)\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n\nThis notebook demonstrated the advanced capabilities of the GRI module:\n\n1. **Monte Carlo Simulations** revealed the theoretical maximum GRI achievable and how the current survey compares\n2. **Segment Analysis** identified specific demographic groups driving representativeness gaps\n3. **Sample Size Analysis** showed the relationship between participant count and achievable GRI scores\n4. **Survey Comparisons** tracked progress across multiple survey iterations\n5. **Alignment Analysis** provided a detailed view of representation patterns\n6. **Comprehensive Reporting** generated shareable reports with actionable insights\n\n### Key Takeaways\n\n- The GRI module significantly reduces code complexity while providing more powerful analysis\n- Monte Carlo simulations help set realistic expectations for achievable representativeness\n- Segment-level analysis provides specific, actionable recruitment targets\n- Built-in visualization and reporting features make it easy to share findings\n\n### Next Steps\n\n1. Use the generated reports to plan recruitment strategies\n2. Focus on the high-priority segments identified in the analysis\n3. Consider the sample size recommendations for future surveys\n4. Track progress by comparing GRI scores across survey iterations\n\nFor more details, see the comprehensive report generated in the `analysis_output` directory.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}